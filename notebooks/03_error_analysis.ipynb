{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62126f76",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "03_error_analysis.py\n",
    "\n",
    "Notebook/script for detailed error analysis of the meter classifier.\n",
    "\n",
    "It:\n",
    "- loads the enriched dataset\n",
    "- loads one of the trained models (baseline or MLP)\n",
    "- computes predictions\n",
    "- uses src.eval_tools to print confusion matrix & top confusions\n",
    "- surfaces concrete misclassified mantras for manual inspection\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bfbb4f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from src.eval_tools import print_confusion_matrix, print_top_confusions\n",
    "from src.model_utils import load_model, features_to_model_input, BASELINE_MODEL_NAME, MLP_MODEL_NAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce7157",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.dirname(os.path.dirname(__file__))\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\", \"processed\")\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "\n",
    "dataset_path = os.path.join(DATA_DIR, \"dataset_enriched.csv\")\n",
    "print(\"Dataset path:\", dataset_path)\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb76257",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Filter down to rows with gold meter labels\n",
    "df = df.dropna(subset=[\"meter_gold_base\"])\n",
    "print(\"Rows with gold base meter:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454e296",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Choose which model to analyze\n",
    "model_name = BASELINE_MODEL_NAME  # or MLP_MODEL_NAME\n",
    "model = load_model(model_name)\n",
    "\n",
    "if model is None:\n",
    "    raise RuntimeError(f\"Model {model_name} not found in {MODEL_DIR}\")\n",
    "\n",
    "print(\"Loaded model:\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6573e5a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare feature matrix consistent with training\n",
    "X = df[[\"L_G_sequence\", \"source_veda\", \"has_pluti\", \"has_stobha\"]]\n",
    "y = df[\"meter_gold_base\"].astype(str)\n",
    "\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776726c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Overall classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a684a04",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "print_confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8bfecf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to DataFrame with predictions\n",
    "df_pred = df.copy()\n",
    "df_pred[\"meter_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d29afa5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Top confusions list\n",
    "print_top_confusions(df_pred, top_k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b3293",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Inspect some concrete errors per meter pair\n",
    "def inspect_confusion(true_meter: str, pred_meter: str, n: int = 5):\n",
    "    subset = df_pred[\n",
    "        (df_pred[\"meter_gold_base\"] == true_meter)\n",
    "        & (df_pred[\"meter_pred\"] == pred_meter)\n",
    "    ]\n",
    "    print(f\"\\n=== Examples where true={true_meter}, pred={pred_meter} (showing {min(n, len(subset))}) ===\")\n",
    "    for _, row in subset.head(n).iterrows():\n",
    "        print(\"ID:\", row[\"id\"])\n",
    "        print(\"source_veda:\", row[\"source_veda\"])\n",
    "        print(\"Chanda raw:\", row[\"meter_gold_raw\"])\n",
    "        print(\"Text:\", row[\"text_dev_original\"])\n",
    "        print(\"L/G:\", row[\"L_G_sequence\"])\n",
    "        print(\"syllable_count_per_pada:\", row[\"syllable_count_per_pada\"])\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# Example: investigate common confusion triṣṭubh ↔ jagatī\n",
    "inspect_confusion(\"trishtubh\", \"jagati\", n=5)\n",
    "inspect_confusion(\"jagati\", \"trishtubh\", n=5)\n",
    "\n",
    "# %%\n",
    "# You can also export misclassified examples for manual spreadsheet review\n",
    "errors = df_pred[df_pred[\"meter_pred\"] != df_pred[\"meter_gold_base\"]]\n",
    "OUT_ERRORS = os.path.join(BASE_DIR, \"data\", \"interim\", \"meter_errors.csv\")\n",
    "os.makedirs(os.path.dirname(OUT_ERRORS), exist_ok=True)\n",
    "errors.to_csv(OUT_ERRORS, index=False)\n",
    "print(\"Wrote misclassified examples to\", OUT_ERRORS)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
